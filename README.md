# Q-s-Free-AI-Chatbot-Mistral-
# ğŸ¤– Q's Free AI Chatbot (Mistral)

A **free, local AI chatbot** powered by the open-source [Mistral model](https://mistral.ai/) through [Ollama](https://ollama.ai/), and built with [Streamlit](https://streamlit.io/).

This chatbot runs **entirely on your computer** â€” no API keys, no cloud costs, just Python and your local model.

---

## ğŸ§© Features
- ğŸ—¨ï¸ Interactive web-based chat UI (built with Streamlit)
- âš¡ Fast local inference using Ollama + Mistral
- ğŸ”’ 100% offline â€” your data never leaves your device
- ğŸ’¾ Saves chat history during session
- ğŸ§° Built fully in Python using `subprocess` and Streamlit components

---

ğŸš€ How to Run It Yourself

### 1ï¸âƒ£ Install Requirements
Make sure you have Python 3.10+ installed. Then open a terminal and install the dependencies:

pip install streamlit
2ï¸âƒ£ Install and Set up Ollama
Download Ollama for your platform:
ğŸ‘‰ https://ollama.ai/download

Then open a terminal (PowerShell on Windows) and pull the Mistral model:
Copy code
ollama pull mistral
3ï¸âƒ£ Clone This Repository
bash
Copy code
git clone https://github.com/QB2134/Q-s-Free-AI-Chatbot-Mistral.git
cd Q-s-Free-AI-Chatbot
4ï¸âƒ£ Run the App
bash
Copy code
streamlit run app.py
Your chatbot will open automatically at http://localhost:8501

ğŸ§© File Overview
File	Description
app.py	Main Streamlit chatbot script
requirements.txt	Python dependencies (optional)
README.md	This documentation file

ğŸ§  How It Works
This app uses Pythonâ€™s subprocess module to send your input text directly to Ollamaâ€™s local model (Mistral). The response is captured and displayed dynamically in a Streamlit chat interface.
Copy code
User Input âœ Python (subprocess) âœ Ollama âœ Mistral Model âœ Response âœ Streamlit UI
ğŸ–¼ï¸ Screenshot

ğŸ§‘â€ğŸ’» About the Author
Qudus
A student and developer exploring computational mathematics, finance, and artificial intelligence.
ğŸ’¼ Connect with me on https://www.linkedin.com/in/qudus-bawa-allah-a226a5242/
